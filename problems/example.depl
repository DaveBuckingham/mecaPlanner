// DEFINE TYPE HEIRARCHY, EVERYTHING MUST BE AN "object".
types{
    robot-actor,
    human-actor,
    actor-person,
    passive-person,
    person-locatable,
    room-location,
    //tool-object,
    locatable-object,
    location-object
}

// DEFINE ALL OBJECTS (I.E. PREDICATE PARAMETERS) AND THEIR TYPES
objects{
    robot1-robot,
    //robot2-robot,
    //human1-passive,
    human2-human,
    room1 - room,
    room2 - room,
    room3 - room,
    //wrench - tool,
    //hammer-tool
}

// DEFINE AGENT NAMES, STARTING WITH THE SYSTEM AGENT
// AND GIVE MODEL CLASS NAMES FOR ANY ENVIRONMENT AGENTS WHOSE ACTIONS SHOULD BE PREDICTED
agents{
    robot1,
    //robot2,
    //human1{},
    human2{TrivialModel}
}

// DEFINE PREDICATES, USE ANGLE BRACKETS TO DEFINE ANY VARIABLES
// VARIABLES WILL FULLY EXPANDED, WITH GROUND PREDICATE FOR EACH VARIABLE VALUATION
predicates{
    at[?a - locatable, ?b - location](?a,?b),
    isTuesday,
    likesDancing[?h-person](?h),
    happy[?h-human](?h),
    //has[?t-tool](human1, ?t),
    //has(human2,wrench),
    //has(human2,hammer),
    //has[?r-robot,?t-tool](?r,?t)
}

constants{
    //canDance(human1),
    //silent(human2)
}

initially{
    isTuesday,

    //at(human1, room1),

    at(human2, room2),
    C(at(human2, room2)),

    at(robot1, room3),

    C(~(B_human2(isTuesday)) & ~(B_human2(~isTuesday))),
    //C(B_human1(isTuesday) | B_human1(~isTuesday)),
    C(B_robot1(isTuesday) | B_robot1(~isTuesday)),

    //C(B_robot1(isTuesday) | B_robot1(~isTuesday)),
    //C(~(B_robot1(isTuesday)) & ~(B_robot1(~isTuesday)))
}

// GOALS ARE ARBITRARY BELIEF FORMULAE
// A GOAL STATE IS ANY STATE THAT SATISFIES ALL THE GOAL FORMULAE
goals{
    at(robot1, room1),
    //at(robot2, room1),
    //B_robot1(isTuesday),
    //B_human1(isTuesday),
    B_human2(isTuesday),
}

// DEFINE ACTIONS A LA (BARAL ET AL 2015)
// AS WITH PREDICATE DEFINITION, VARIABLES CAN BE EXPANED
// AT THE ACTION LEVEL OR AT THE LEVEL OF INDIVIDUAL FIELDS
// VARIABLE SCOPE WILL BE RESPECTED
actions{
    move[?f-location,?t-location,?a-actor](?f,?t){
        owner{?a},                                             // mandatory, not repeatable, who's action is it
        //cost{1},                                               // optional, not repeatable, the default is 1
        precondition{at(?a, ?f)},                              // optional, repeatable, belief formulae
        precondition{~at(?a, ?t)},                              // optional, repeatable, belief formulae
        //observesif[?o - person]{?o, (at(?o,?f) | at(?o,?t))},   // optional, repeatable, takes an agent and a fluent formula condition
        //observes[?o - person]{?o},
        observes{robot1},
        observes{human2},
        causes{at(?a, ?t)},                                    // optional, repeatable, makes this an *ontic* action, a fluent literal
        causes{~(at(?a, ?f))},
    }

    tellTuesday[](){
        owner{robot1},
        //constraint{~silent(robot1)},
        observes[?o-actor]{?o},                                // same as observesif but the condition is always true
        announces{isTuesday}                                   // optional, not repeatable, makes this an *announcemnt* action, a fluent formula
    }
//
//    dance[?a - human]() {
//        owner{?a},
//        //cost{2},
//        constraint{canDance(?a)},
//        observes[?o-actor]{?o},                                // everyone can see you dance
//        causesif{happy(?a), likesDancing(?a)}                  // conditional effect, conditioned by a belief formula
//    }

//    checkCalendar[?a - robot]() {
//        owner{?a},
//        cost{2},
//        observes{?a},
//        determines{isTuesday}
//    }

//    wait[?a - actor]() {
//        owner{?a},
//        cost{1},
//        observes{?a},
//    }

    // need to add:
    // a sensing action example
    // aware
}
